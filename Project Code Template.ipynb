{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Code\"\n",
    "subtitle: Team Zzz\n",
    "author: Aarti Pappu, Divya Bhardwaj, Diego Schummer, and Yasmeen Nahas \n",
    "date: 06/07/2023\n",
    "number-sections: true\n",
    "abstract: _This file contains the code for the project on <>, as part of the STAT303-3 course in Spring 2023_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "execute:\n",
    "  warning: false\n",
    "  error: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5c3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix, mean_absolute_error, f1_score, cohen_kappa_score, matthews_corrcoef, classification_report\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier,BaggingRegressor,BaggingClassifier, \\\n",
    "AdaBoostRegressor,AdaBoostClassifier,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from pyearth import Earth\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.** An example is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a5a4a",
   "metadata": {},
   "source": [
    "### Distribution of response\n",
    "*By Sylvia Sherwood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Plot for distribution of response...#\n",
    "\n",
    "# Mean and standard deviation of response #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b5e83",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "*By Sankaranarayanan Balasubramanian & Fiona Fe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddf4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Code with comments...#\n",
    "\n",
    "# Imputing missing values #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424479b5",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "*By Ryu Kimiko*\n",
    "\n",
    "The following data preparation steps helped us to prepare our data for implementing various modeling / validation techniques:\n",
    "\n",
    "1. Since we need to predict house price, we derived some new predictors *(from existing predictors)* that intuitively seem to be helpuful to predict house price. \n",
    "\n",
    "2. We have created a standardized version of the dataset, as we will use it to develop Lasso / Ridge regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde6859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######---------------Creating new predictors----------------#########\n",
    "\n",
    "#Creating number of bedrooms per unit floor area\n",
    "\n",
    "#Creating ratio of bathrooms to bedrooms\n",
    "\n",
    "#Creating ratio of carpet area to floor area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######-----Standardizing the dataset for Lasso / Ridge-------#########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**\n",
    "\n",
    "Put each model in a section of its name and mention the name of the team-member tuning the model. Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b73426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data from the created csv files\n",
    "X_train = pd.read_csv('X_train_stratified.csv')\n",
    "y_train = pd.read_csv('y_train_stratified.csv')\n",
    "X_test = pd.read_csv('X_test_stratified.csv')\n",
    "y_test = pd.read_csv('y_test_stratified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc9dcc",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "*By Aarti Pappu*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40129731",
   "metadata": {},
   "source": [
    "First, I started with a basic model to better understand the ranges of the different hyperparameters of the decision tree so I could know where to start my tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71cc225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of leaves: 1037\n",
      "Maximum depth: 25\n",
      "Maximum features: 11\n"
     ]
    }
   ],
   "source": [
    "# Defining the object to build a regression tree\n",
    "model = DecisionTreeClassifier(random_state=1) \n",
    "\n",
    "#Fitting the regression tree to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Maximum number of leaves:\", model.get_n_leaves())\n",
    "print(\"Maximum depth:\", model.get_depth())\n",
    "print(\"Maximum features:\", len(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d63e3",
   "metadata": {},
   "source": [
    "Using the hyperparameter ranges obtained, as well as my intuition about other hyperparameters that could be important in tuning the tree (`min_samples_leaf` and `min_samples_split`), I did a course grid search to try to narrow the range of the optimal hyperparameters. I then plotted the results of the coarse grid search to better understand the ranges of the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse grid search parameter grid\n",
    "param_grid = {    \n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth': range(2,26,5),\n",
    "    'max_leaf_nodes': range(2,1038,100),\n",
    "    'max_features': range(1, 12,3),\n",
    "    'min_samples_leaf': range(1,10,2),\n",
    "    'min_samples_split': range(2,10,2)\n",
    "}\n",
    "\n",
    "# using 2-fold CV because of the limited number of instances of some of the classes \n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "\n",
    "# aiming to maximize F1-score\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, scoring=['f1_weighted','accuracy'], refit= 'f1_weighted', cv=skf, n_jobs=-1, verbose = True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# make the predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print('Train F1-score : %.3f'%grid_search.best_estimator_.score(X_train, y_train))\n",
    "print('Test F1-score : %.3f'%grid_search.best_estimator_.score(X_test, y_test))\n",
    "print('Best F1-score Through Grid Search : %.3f'%grid_search.best_score_)\n",
    "\n",
    "print('Best params for F1-score')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b91cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "fig, axes = plt.subplots(3,2,figsize=(18,20))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "axes[0,0].plot(cv_results.param_max_depth, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[0,0].set_ylim([0,1])\n",
    "axes[0,0].set_xlabel('max_depth')\n",
    "axes[0,0].set_ylabel('K-fold F1 Score')\n",
    "axes[0,1].plot(cv_results.param_max_leaf_nodes, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[0,1].set_ylim([0,1])\n",
    "axes[0,1].set_xlabel('max_leaf_nodes')\n",
    "axes[0,1].set_ylabel('K-fold F1 Score')\n",
    "axes[1,0].plot(cv_results.param_max_features, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[1,0].set_ylim([0,1])\n",
    "axes[1,0].set_xlabel('max_features')\n",
    "axes[1,0].set_ylabel('K-fold F1 Score')\n",
    "axes[1,1].plot(cv_results.param_min_samples_leaf, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[1,1].set_ylim([0,1])\n",
    "axes[1,1].set_xlabel('min_samples_leaf')\n",
    "axes[1,1].set_ylabel('K-fold F1 Score')\n",
    "axes[2,0].plot(cv_results.param_min_samples_split, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[2,0].set_ylim([0,1])\n",
    "axes[2,0].set_xlabel('min_samples_split')\n",
    "axes[2,0].set_ylabel('K-fold F1 Score')\n",
    "axes[2,1].plot(cv_results.param_criterion, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[2,1].set_ylim([0,1])\n",
    "axes[2,1].set_xlabel('criterion')\n",
    "axes[2,1].set_ylabel('K-fold F1 Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer grid search\n",
    "param_grid = {    \n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth': range(8,26,2),\n",
    "    'max_leaf_nodes': range(100,1038,50),\n",
    "    'max_features': range(1,12,2)\n",
    "}\n",
    "\n",
    "\n",
    "#Grid search to optimize parameter values\n",
    "skf = StratifiedKFold(n_splits=2)#The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "#Minimizing FNR is equivalent to maximizing recall\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, scoring=['f1_weighted','accuracy'], refit= 'f1_weighted', cv=skf, n_jobs=-1, verbose = True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# make the predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print('Train F1-score : %.3f'%grid_search.best_estimator_.score(X_train, y_train))\n",
    "print('Test F1-score : %.3f'%grid_search.best_estimator_.score(X_test, y_test))\n",
    "print('Best F1-score Through Grid Search : %.3f'%grid_search.best_score_)\n",
    "\n",
    "print('Best params for F1-score')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "fig, axes = plt.subplots(2,2,figsize=(18,15))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "axes[0,0].plot(cv_results.param_max_depth, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[0,0].set_ylim([0.4,0.6])\n",
    "axes[0,0].set_xlabel('max_depth')\n",
    "axes[0,0].set_ylabel('K-fold F1 Score')\n",
    "axes[0,1].plot(cv_results.param_max_leaf_nodes, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[0,1].set_ylim([0.4,0.6])\n",
    "axes[0,1].set_xlabel('max_leaf_nodes')\n",
    "axes[0,1].set_ylabel('K-fold F1 Score')\n",
    "axes[1,0].plot(cv_results.param_max_features, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[1,0].set_ylim([0.4,0.6])\n",
    "axes[1,0].set_xlabel('max_features')\n",
    "axes[1,0].set_ylabel('K-fold F1 Score')\n",
    "axes[1,1].plot(cv_results.param_criterion, cv_results.mean_test_f1_weighted, 'o')\n",
    "axes[1,1].set_ylim([0.4,0.6])\n",
    "axes[1,1].set_xlabel('criterion')\n",
    "axes[1,1].set_ylabel('K-fold F1 Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finer grid search\n",
    "param_grid = { \n",
    "    'max_depth': range(16,26),\n",
    "    'max_leaf_nodes': range(550,1038),\n",
    "    'max_features': range(1,5)\n",
    "}\n",
    "\n",
    "\n",
    "#Grid search to optimize parameter values\n",
    "skf = StratifiedKFold(n_splits=2)#The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "#Minimizing FNR is equivalent to maximizing recall\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, scoring=['f1_weighted','accuracy'], refit= 'f1_weighted', cv=skf, n_jobs=-1, verbose = True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# make the predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print('Train F1-score : %.3f'%grid_search.best_estimator_.score(X_train, y_train))\n",
    "print('Test F1-score : %.3f'%grid_search.best_estimator_.score(X_test, y_test))\n",
    "print('Best F1-score Through Grid Search : %.3f'%grid_search.best_score_)\n",
    "\n",
    "print('Best params for F1-score')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Random Forest classifier with the best parameters\n",
    "model = DecisionTreeClassifier(random_state=1, max_depth=17, max_features = 4, max_leaf_nodes=613)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "feature_importance_df = pd.concat([pd.Series(model.feature_names_in_), pd.Series(model.feature_importances_)], axis = 1)\n",
    "feature_importance_df.rename(columns={0: \"predictors\", 1: \"feature_importance\"}).sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c9ff7",
   "metadata": {},
   "source": [
    "### Bagged Decision Trees\n",
    "*By Divya Bhardwaj*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ca069",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "*By Diego Schummer*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182968b",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "*By Yasmeen Nahas*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221dcc6",
   "metadata": {},
   "source": [
    "## Model Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8b3d9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bcb1d",
   "metadata": {},
   "source": [
    "### Voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca651ba0",
   "metadata": {},
   "source": [
    "### Stacking ensemble(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff3adf",
   "metadata": {},
   "source": [
    "### Ensemble of ensembled models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668faab",
   "metadata": {},
   "source": [
    "### Innovative ensembling methods\n",
    "*(Optional)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "You may or may not have code to put in this section. Delete this section if it is irrelevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
