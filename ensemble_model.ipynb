{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9aee0e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): [\"dlopen(/Users/diegoschummer/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: <B6C96776-4964-3D36-87A1-9BA40923D8B8> /Users/diegoschummer/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-90a48c7b0833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;34m'`brew install libomp` to install OpenMP runtime.\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): [\"dlopen(/Users/diegoschummer/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: <B6C96776-4964-3D36-87A1-9BA40923D8B8> /Users/diegoschummer/anaconda3/envs/hw_2/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc,precision_recall_curve, accuracy_score, \\\n",
    "recall_score, precision_score, confusion_matrix, mean_absolute_error, classification_report\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier,BaggingRegressor,BaggingClassifier, \\\n",
    "AdaBoostRegressor,AdaBoostClassifier,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import VotingRegressor, VotingClassifier\n",
    "from pyearth import Earth\n",
    "import itertools as it\n",
    "import time as time\n",
    "import xgboost as xgb\n",
    "import re \n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5bef6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_stratified.csv')\n",
    "y_train = pd.read_csv('y_train_stratified.csv')\n",
    "X_test = pd.read_csv('X_test_stratified.csv')\n",
    "y_test = pd.read_csv('y_test_stratified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "233d47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/m0/5bk_k6ld73d91p0p4lfvfrvh0000gn/T/ipykernel_3120/2960407568.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_model = RandomForestClassifier(criterion='entropy', max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100,\n",
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# all models\n",
    "dt_model = DecisionTreeClassifier(random_state=1, max_depth=17, max_features = 4, max_leaf_nodes=613).fit(X_train,y_train)\n",
    "bg_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=1), n_estimators=300, random_state=1,max_features=7, \n",
    "                             max_samples=2500, bootstrap=False,bootstrap_features=False).fit(X_train, y_train)\n",
    "rf_model = RandomForestClassifier(criterion='entropy', max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100, \n",
    "                                  max_features = 2, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_xgb = le.fit_transform(y_train)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective = 'multi:softmax',random_state = 1, gamma = 0.06, learning_rate = 0.3, max_depth = 9,\n",
    "                              n_estimators = 150, reg_lambda = 1.0, subsample = 0.8, num_class = 7).fit(X_train, y_train_xgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2058cd0",
   "metadata": {},
   "source": [
    "# train data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17b19cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data:\n",
    "dt_pred = dt_model.predict(X_train)\n",
    "bg_pred = bg_model.predict(X_train)\n",
    "rf_pred = rf_model.predict(X_train)\n",
    "xgb_pred = xgb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "133e8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the xgb_predictions back to original classes\n",
    "xgb_pred[xgb_pred == 0] = 3\n",
    "xgb_pred[xgb_pred == 1] = 4\n",
    "xgb_pred[xgb_pred == 2] = 5\n",
    "xgb_pred[xgb_pred == 3] = 6\n",
    "xgb_pred[xgb_pred == 4] = 7\n",
    "xgb_pred[xgb_pred == 5] = 8\n",
    "xgb_pred[xgb_pred == 6] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8125c068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7, 7],\n",
       "       [7, 7, 7, 7],\n",
       "       [5, 5, 5, 8],\n",
       "       ...,\n",
       "       [5, 5, 5, 8],\n",
       "       [7, 7, 7, 7],\n",
       "       [7, 6, 6, 9]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.hstack((dt_pred.reshape(-1,1),bg_pred.reshape(-1,1),rf_pred.reshape(-1,1), xgb_pred.reshape(-1,1)))\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "096b6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_elements_train = []\n",
    "for i in range(3918):\n",
    "    c = Counter(list(all_preds[i]))\n",
    "    c.most_common()\n",
    "    value, count = c.most_common()[0]\n",
    "    majority_elements_train.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a68abf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       1.00      0.98      0.99       130\n",
      "           5       1.00      1.00      1.00      1166\n",
      "           6       1.00      1.00      1.00      1758\n",
      "           7       1.00      1.00      1.00       704\n",
      "           8       1.00      1.00      1.00       140\n",
      "           9       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00      3918\n",
      "   macro avg       1.00      1.00      1.00      3918\n",
      "weighted avg       1.00      1.00      1.00      3918\n",
      "\n",
      "[[  16    0    0    0    0    0    0]\n",
      " [   0  127    0    0    3    0    0]\n",
      " [   0    0 1166    0    0    0    0]\n",
      " [   0    0    0 1758    0    0    0]\n",
      " [   0    0    0    0  704    0    0]\n",
      " [   0    0    0    0    0  140    0]\n",
      " [   0    0    0    0    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, majority_elements_train))\n",
    "print(confusion_matrix(y_train, majority_elements_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78ee93",
   "metadata": {},
   "source": [
    "# test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "641d4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data:\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "bg_pred = bg_model.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "xgb_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3621b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the xgb_predictions back to original classes\n",
    "xgb_pred[xgb_pred == 0] = 3\n",
    "xgb_pred[xgb_pred == 1] = 4\n",
    "xgb_pred[xgb_pred == 2] = 5\n",
    "xgb_pred[xgb_pred == 3] = 6\n",
    "xgb_pred[xgb_pred == 4] = 7\n",
    "xgb_pred[xgb_pred == 5] = 8\n",
    "xgb_pred[xgb_pred == 6] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a2e88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.00      0.00      0.00       291\n",
      "           6       0.00      0.00      0.00       440\n",
      "           7       0.60      0.53      0.56       176\n",
      "           8       0.07      0.60      0.12        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.12       980\n",
      "   macro avg       0.10      0.16      0.10       980\n",
      "weighted avg       0.11      0.12      0.11       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fea94f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.hstack((dt_pred.reshape(-1,1),bg_pred.reshape(-1,1),rf_pred.reshape(-1,1), xgb_pred.reshape(-1,1)))\n",
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e318eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_elements_test = []\n",
    "for i in range(980):\n",
    "    c = Counter(list(all_preds[i]))\n",
    "    c.most_common()\n",
    "    value, count = c.most_common()[0]\n",
    "    majority_elements_test.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e34a299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.58      0.21      0.31        33\n",
      "           5       0.72      0.64      0.68       291\n",
      "           6       0.63      0.78      0.70       440\n",
      "           7       0.64      0.52      0.58       176\n",
      "           8       0.90      0.54      0.68        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66       980\n",
      "   macro avg       0.50      0.39      0.42       980\n",
      "weighted avg       0.66      0.66      0.65       980\n",
      "\n",
      "[[  0   0   1   3   0   0   0]\n",
      " [  0   7  15  10   1   0   0]\n",
      " [  1   3 186 100   1   0   0]\n",
      " [  0   1  55 344  40   0   0]\n",
      " [  0   0   3  79  92   2   0]\n",
      " [  0   1   0   7   8  19   0]\n",
      " [  0   0   0   0   1   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aartipappu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Test data:\n",
    "print(classification_report(y_test, majority_elements_test))\n",
    "print(confusion_matrix(y_test, majority_elements_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1eb76b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd188f6a35e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Decision Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m dt_feature_importances = pd.DataFrame(dt_model.feature_importances_,\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                       \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#get important features from each model average them\n",
    "\n",
    "# Decision Tree\n",
    "dt_feature_importances = pd.DataFrame(dt_model.feature_importances_,\n",
    "\n",
    "                                      index = X_train.columns,              \n",
    "\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "dt_feature_importances.head(10)\n",
    "\n",
    "# Bagging\n",
    "bg_feature_importances = pd.DataFrame(bg_model.feature_importances_,\n",
    "\n",
    "                                        index = X_train.columns,            \n",
    "\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "bg_feature_importances.head(10) \n",
    "\n",
    "# Random Forest\n",
    "\n",
    "rf_feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "\n",
    "                                        index = X_train.columns,        \n",
    "\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "rf_feature_importances.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095a839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "627ab9810584fcc3b5dcfd2a7a77b5523f6f9b9903be318bb2f0d057cf72be58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
